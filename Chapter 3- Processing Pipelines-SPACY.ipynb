{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Processing Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome back! This chapter is dedicated to processing pipelines: a series of functions applied to a Doc to add attributes like part-of-speech tags, dependency labels or named entities.\n",
    "\n",
    "In this lesson, you'll learn about the pipeline components provided by spaCy, and what happens behind the scenes when you call nlp on a string of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Built-in pipeline components\n",
    "Name\tDescription\tCreates\n",
    "tagger\tPart-of-speech tagger\tToken.tag\n",
    "parser\tDependency parser\tToken.dep, Token.head, Doc.sents, Doc.noun_chunks\n",
    "ner\tNamed entity recognizer\tDoc.ents, Token.ent_iob, Token.ent_type\n",
    "textcat\tText classifier\tDoc.cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy ships with the following built-in pipeline components.\n",
    "\n",
    "The part-of-speech tagger sets the token dot tag attribute.\n",
    "\n",
    "The dependency parser adds the token dot dep and token dot head attributes and is also responsible for detecting sentences and base noun phrases, also known as noun chunks.\n",
    "\n",
    "The named entity recognizer adds the detected entities to the doc dot ents property. It also sets entity type attributes on the tokens that indicate if a token is part of an entity or not.\n",
    "\n",
    "Finally, the text classifier sets category labels that apply to the whole text, and adds them to the doc dot cats property.\n",
    "\n",
    "Because text categories are always very specific, the text classifier is not included in any of the pre-trained models by default. But you can use it to train your own system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Under the Hood\n",
    "All models you can load into spaCy include several files and a meta JSON.\n",
    "\n",
    "The meta defines things like the language and pipeline. This tells spaCy which components to instantiate.\n",
    "\n",
    "The built-in components that make predictions also need binary data. The data is included in the model package and loaded into the component when you load the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline defined in model's meta.json in order.\n",
    "\n",
    "Built-in components need binary data to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
